# **RecognAVSE-V2: An Improved Cross-Attention-Based Audio-Visual Speech Enhancement Approach**

## **Overview**
RecognAVSE-V2 is an audio-visual speech enhancement (AVSE) model that builds upon RecognAVSE. It introduces an attention mechanism to improve temporal modeling while reducing computational costs. The model aligns audio and visual features to enhance speech intelligibility in noisy environments.

## **Features**
- **Attention-Based Audio-Visual Speech Enhancement**: Uses an attention mechanism to refine temporal relationships between modalities.
- **Lightweight Architecture**: More efficient, 20Ã— smaller and faster than RecognAVSE.
- **Performance Improvements**: Achieves higher PESQ, STOI, and SISDR scores on the CHiME3 dataset.
- **Handling of Overlapping Speech**: Designed to process speech in challenging conditions, including concurrent speakers.

## **Code Release**
The code will be made publicly available upon paper acceptance.

## **Citation**
If you find this work useful, please consider citing our paper (citation details will be shared upon acceptance).

## **Contact**
For questions or collaboration inquiries, feel free to reach out.
